{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d74572580e24b09f3bbd0ec9d74bde002234be0"
   },
   "source": [
    "Existing model is forked From [https://github.com/ashishpatel26/Facial-Expression-Recognization-using-JAFFE](http://) . But I have removed the labeling error and changed the CNN Model .  I have also updated the existing model that gives better accuracy than previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgust', 'anger', 'sadness', 'surprise', 'contempt', 'fear', 'happy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input/ckplus/ck/CK+48\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imageSize=80\n",
    "test_dir = '../input/ckplus/ck/CK+48/'\n",
    "\n",
    "# ['DME', 'CNV', 'NORMAL', '.DS_Store', 'DRUSEN']\n",
    "from tqdm import tqdm\n",
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['disgust']:\n",
    "                label = 0\n",
    "            elif folderName in ['anger']:\n",
    "                label = 1\n",
    "            elif folderName in ['sadness']:\n",
    "                label = 2\n",
    "            elif folderName in ['surprise']:\n",
    "                label = 3\n",
    "            elif folderName in ['contempt']:\n",
    "                label = 4\n",
    "            elif folderName in ['fear']:\n",
    "                label = 5\n",
    "            elif folderName in ['fear']:\n",
    "                 label = 6\n",
    "            else:\n",
    "                label = 7\n",
    "\n",
    "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
    "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 1))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X) # Keras only accepts data as numpy arrays \n",
    "    y = np.asarray(y)\n",
    "    return X,y\n",
    "X_test, y_test = get_data(test_dir) # Un-comment to use full dataset: Step 1 of 2\n",
    "#X_test, y_test= get_data(train_dir)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_test, y_test, test_size=0.2) # comment this ligne  to use full dataset: Step 2 of 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "be0ca550e4cd455834b3177a5ee43c33801cfe11",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "colab_type": "code",
    "id": "ODyVs_urTCSH",
    "outputId": "3954b8fb-c4b7-4f38-a59f-8c3be26b6217"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import itertools\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../input/ckplus/ck/CK+48'\n",
    "labels = os.listdir('../input/ckplus/ck/CK+48')\n",
    "train_datagen = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=15, \n",
    "                              zoom_range=0.15,\n",
    "                              validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "batch_size = 36\n",
    "train_data_dir = '../input/ckplus/ck/CK+48'\n",
    "validation_data_dir = '../input/ckplus/ck/CK+48'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_SIZE , IMG_SIZE),\n",
    "    batch_size=36,\n",
    "    subset='training',\n",
    "    class_mode='categorical')\n",
    "valid_X, valid_Y = next(train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_SIZE , IMG_SIZE),\n",
    "    batch_size=94,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x, t_y = next(train_generator)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(labels, c_y) \n",
    "                             if n_score>0.5]))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=( 224, 224, 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "model.add(Conv2D(412, (5, 5), padding='same', activation = 'relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# Classification\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "#Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch=887/36,\n",
    "                                  validation_data = (valid_X,valid_Y), \n",
    "                                  epochs = 50\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(valid_X,valid_Y, verbose=0)\n",
    "print('\\n Model accuracy ON TEST SET :', score[1], '\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsFaces =['disgust', 'anger', 'sadness', 'surprise', 'contempt', 'fear', 'happy']\n",
    "\n",
    "\n",
    "predictedExpression = model.predict(valid_X)\n",
    "\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "\n",
    "for i, index in enumerate(np.random.choice(valid_X.shape[0], size=25, replace=False)):\n",
    "    ax = figure.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(valid_X[index]))\n",
    "    predict_index = np.argmax(predictedExpression[index])\n",
    "    true_index = np.argmax(valid_Y[index])\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(labelsFaces[predict_index], \n",
    "                                  labelsFaces[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FEAR', 'ANGRY', 'SURPRISE', 'DISGUST', 'SAD', 'HAPPY', 'NEUTRAL']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/jaffefacialexpression/jaffe/jaffe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2ccc8d12aa2c567760421bd87d536144f00ae90",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "uQI820JhUYj9",
    "outputId": "0c96a197-6b10-454a-bc23-c23b3fbf6056"
   },
   "outputs": [],
   "source": [
    "data_path = '../input/jaffefacialexpression/jaffe/jaffe'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=256\n",
    "img_cols=256\n",
    "num_channel=1\n",
    "\n",
    "num_epoch=10\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(224,224))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        \n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1079555608d0b0036a349af00f76481caa79eebd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hbOl7E-8UcX9",
    "outputId": "00424152-50c9-422f-ed15-117c33ebe6dc"
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:29]=0 #30\n",
    "labels[30:58]=1 #29\n",
    "labels[59:90]=2 #32\n",
    "labels[91:121]=3 #31\n",
    "labels[122:151]=4 #30\n",
    "labels[152:182]=5 #31\n",
    "labels[183:]=6 #30\n",
    "\n",
    "names = ['ANGRY','DISGUST','FEAR','HAPPY','NEUTRAL','SAD','SURPRISE']\n",
    "\n",
    "def getLabel(id):\n",
    "    return ['ANGRY','DISGUST','FEAR','HAPPY','NEUTRAL','SAD','SURPRISE'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "29f2c1a4c161db04c594667fc55023a6e5da0be8",
    "colab": {},
    "colab_type": "code",
    "id": "xUmcqKiMUgZk"
   },
   "outputs": [],
   "source": [
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
    "x_test=X_test\n",
    "#X_train=X_train.reshape(X_train.shape[0],128,128,1)\n",
    "#X_test=X_test.reshape(X_test.shape[0],128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89517c9ec41b09ed60e4d005a08fb7fe78ac2eb0"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4425acad3bc8aa0019f50e0b29c7ce4e1eeb7d57",
    "colab": {},
    "colab_type": "code",
    "id": "UEcO-PMyUkhO"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(224,224,3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(258, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    " \n",
    "#Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\n",
    "model.layers[0].output_shape\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "filename='model1_train_new.csv'\n",
    "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "\n",
    "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [csv_log,checkpoint]\n",
    "callbacks_list = [csv_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing losses and accuracy\n",
    "%matplotlib inline\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "\n",
    "epochs = range(len(train_acc))\n",
    "\n",
    "plt.plot(epochs,train_loss,'r', label='train_loss')\n",
    "plt.plot(epochs,val_loss,'b', label='val_loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,train_acc,'r', label='train_acc')\n",
    "plt.plot(epochs,val_acc,'b', label='val_acc')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b59b01ab135eca80576a5915c4a1fae0721328f2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "YpCL9im7VHpC",
    "outputId": "1ad4d180-1c8b-43c9-9399-a25e79194520"
   },
   "outputs": [],
   "source": [
    "input_shape=(224,224,3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "888f7ccffbe9b2a0e7f5eea9886509c4c2da53b7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "Gjmj9Cz3VT1b",
    "outputId": "2ffb75fb-f6eb-4f49-8afe-68e86641b5f4"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\n",
    "model.layers[0].output_shape\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36548e567c32aa7fe143611962071bb306b0e0fb",
    "colab": {},
    "colab_type": "code",
    "id": "8CNczAIPVhDy"
   },
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "filename='model_train_new.csv'\n",
    "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "\n",
    "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [csv_log,checkpoint]\n",
    "callbacks_list = [csv_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b44a3fe424841532a630635f4702c1f980f2b3ac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1980
    },
    "colab_type": "code",
    "id": "7s8Uy0G8WnTa",
    "outputId": "a5ce06fa-576f-47b0-b6d8-da606e32fd7f"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5dca58ec635d18a8baf11fc70ec826da6e9f3c1e",
    "colab": {},
    "colab_type": "code",
    "id": "tYAXlAm7WzSw"
   },
   "outputs": [],
   "source": [
    "#Model Save\n",
    "model.save_weights('model_weights.h5')\n",
    "model.save('model_keras.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e0d02f0f04af3345997c0236194c2ff7937c1dc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "Enxigu7LYX5e",
    "outputId": "05f9582a-efd7-41ee-a2ae-0443a9b13440"
   },
   "outputs": [],
   "source": [
    "# visualizing losses and accuracy\n",
    "%matplotlib inline\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "\n",
    "epochs = range(len(train_acc))\n",
    "\n",
    "plt.plot(epochs,train_loss,'r', label='train_loss')\n",
    "plt.plot(epochs,val_loss,'b', label='val_loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,train_acc,'r', label='train_acc')\n",
    "plt.plot(epochs,val_acc,'b', label='val_acc')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5de70c87dc739e401ddc27262eea4433fa34d9f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "colab_type": "code",
    "id": "nvqxVr7qYbxX",
    "outputId": "3554ef0e-d6b6-4956-ef8a-6ff78f88246c"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_image = X_test[0:1]\n",
    "print (test_image.shape)\n",
    "\n",
    "print(model.predict(test_image))\n",
    "print(model.predict_classes(test_image))\n",
    "print(y_test[0:1])\n",
    "\n",
    "res = model.predict_classes(X_test[9:18])\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(x_test[i],cmap=plt.get_cmap('gray'))\n",
    "    plt.gca().get_xaxis().set_ticks([])\n",
    "    plt.gca().get_yaxis().set_ticks([])\n",
    "    plt.ylabel('prediction = %s' % getLabel(res[i]), fontsize=14)\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dac2263fcba5f2d1bbd0d3eceb3df32843f51f93",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "1Y1ASlPjYgZY",
    "outputId": "fd0767e8-5066-4bfc-dc84-4b758dfc2157"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = model.predict_classes(X_test)\n",
    "cm = confusion_matrix(np.where(y_test == 1)[1], results)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 105.53it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 109.89it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 110.77it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 110.27it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 108.04it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 108.15it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 107.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imageSize=80\n",
    "test_dir = '../input/jaffefacialexpression/jaffe/jaffe/'\n",
    "\n",
    "# ['DME', 'CNV', 'NORMAL', '.DS_Store', 'DRUSEN']\n",
    "from tqdm import tqdm\n",
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['disgust']:\n",
    "                label = 0\n",
    "            elif folderName in ['anger']:\n",
    "                label = 1\n",
    "            elif folderName in ['sadness']:\n",
    "                label = 2\n",
    "            elif folderName in ['surprise']:\n",
    "                label = 3\n",
    "            elif folderName in ['contempt']:\n",
    "                label = 4\n",
    "            elif folderName in ['fear']:\n",
    "                label = 5\n",
    "            elif folderName in ['fear']:\n",
    "                 label = 6\n",
    "            else:\n",
    "                label = 7\n",
    "\n",
    "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
    "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 1))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X) # Keras only accepts data as numpy arrays \n",
    "    y = np.asarray(y)\n",
    "    return X,y\n",
    "X_test, y_test = get_data(test_dir) # Un-comment to use full dataset: Step 1 of 2\n",
    "#X_test, y_test= get_data(train_dir)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_test, y_test, test_size=0.2) # comment this ligne  to use full dataset: Step 2 of 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtest shape (43, 6400)\n",
      "X_train1 shape (170, 6400)\n",
      "y_train shape (170,)\n",
      "y_test shape (43,)\n"
     ]
    }
   ],
   "source": [
    "m_samples = X_train.shape[0]\n",
    "m_samplesTest = X_test.shape[0]\n",
    "X_train1 = X_train.reshape(m_samples, -1)\n",
    "X_test1 = X_test.reshape(m_samplesTest, -1)\n",
    " \n",
    "print('Xtest shape',X_test1.shape)\n",
    "print('X_train1 shape',X_train1.shape)\n",
    "print('y_train shape',y_train.shape)\n",
    "print('y_test shape',y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Xtest shape',X_test1.shape)\n",
    "print('X_train1 shape',X_train1.shape)\n",
    "print('y_train shape',y_train.shape)\n",
    "print('y_test shape',y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train1,y_train)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "y_pred = clf.predict(X_test1)\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree Accuracy CK48 : 1.0\n",
      "F1 score :  1.0\n",
      "recall_score :  1.0\n",
      "precision_score :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Decision tree Accuracy CK48 :\",metrics.accuracy_score(y_test, y_pred))\n",
    "print('F1 score : ',f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('recall_score : ',recall_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('precision_score : ',precision_score(y_test,y_pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifierG = XGBClassifier()\n",
    "classifierG.fit(X_train1,y_train)\n",
    "# Predicting the Test set results\n",
    "y_predXG = classifierG.predict(X_test1)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST  Accuracy ON CK48 data: 1.0\n",
      "F1 score :  1.0\n",
      "recall_score :  1.0\n",
      "precision_score :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"XGBOOST  Accuracy ON CK48 data:\",metrics.accuracy_score(y_test, y_predXG))\n",
    "print('F1 score : ',f1_score(y_test,y_predXG,average=\"weighted\"))\n",
    "print('recall_score : ',recall_score(y_test,y_predXG,average=\"weighted\"))\n",
    "print('precision_score : ',precision_score(y_test,y_predXG,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=300,class_weight='balanced',n_jobs=2,random_state=42)\n",
    "rf.fit(X_train1,y_train)\n",
    "pred=rf.predict(X_test1)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier  Accuracy ON CK48 data: 1.0\n",
      "F1 score :  1.0\n",
      "recall_score :  1.0\n",
      "precision_score :  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier  Accuracy ON CK48 data:\",metrics.accuracy_score(y_test, pred))\n",
    "print('F1 score : ',f1_score(y_test,pred,average=\"weighted\"))\n",
    "print('recall_score : ',recall_score(y_test,pred,average=\"weighted\"))\n",
    "print('precision_score : ',precision_score(y_test,pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train1,y_train)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "y_pred = clf.predict(X_test1)\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Decision tree Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print('F1 score : ',f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('recall_score : ',recall_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('precision_score : ',precision_score(y_test,y_pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifierG = XGBClassifier()\n",
    "classifierG.fit(X_train1,y_train)\n",
    "# Predicting the Test set results\n",
    "y_predXG = classifierG.predict(X_test1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"XGBOOST  Accuracy ON JAFFE data:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print('F1 score : ',f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('recall_score : ',recall_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('precision_score : ',precision_score(y_test,y_pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train1,y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"SVM  Accuracy ON JAFFE data:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print('F1 score : ',f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('recall_score : ',recall_score(y_test,y_pred,average=\"weighted\"))\n",
    "print('precision_score : ',precision_score(y_test,y_pred,average=\"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Jaffe Facial Expression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
